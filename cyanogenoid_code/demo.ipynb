{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "import config\n",
    "import model_batchnormDP0\n",
    "import model_batchnormDP05\n",
    "import model_dropout0\n",
    "import model_dropout05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NET ONE\n",
    "log = torch.load('logs/batchnormDP0.pth')\n",
    "tokens = len(log['vocab']['question']) + 1\n",
    "net1 = torch.nn.DataParallel(model_batchnormDP0.Net(tokens)).cuda()\n",
    "net1.load_state_dict(log['weights'])\n",
    "# NET TWO\n",
    "log = torch.load('logs/batchnormDP05.pth')\n",
    "tokens = len(log['vocab']['question']) + 1\n",
    "net2 = torch.nn.DataParallel(model_batchnormDP05.Net(tokens)).cuda()\n",
    "net2.load_state_dict(log['weights'])\n",
    "# NET THREE\n",
    "log = torch.load('logs/dropout0.pth')\n",
    "tokens = len(log['vocab']['question']) + 1\n",
    "net3 = torch.nn.DataParallel(model_dropout0.Net(tokens)).cuda()\n",
    "net3.load_state_dict(log['weights'])\n",
    "# NET FOUR\n",
    "log = torch.load('logs/dropout05.pth')\n",
    "tokens = len(log['vocab']['question']) + 1\n",
    "net4 = torch.nn.DataParallel(model_dropout05.Net(tokens)).cuda()\n",
    "net4.load_state_dict(log['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'I' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-34f465c99ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                                      std=[0.5, 0.5, 0.5]),\n\u001b[1;32m     13\u001b[0m             ])\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mI_tens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mbackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtens_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_tens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I' is not defined"
     ]
    }
   ],
   "source": [
    "for net_i, net in enumerate([net1, net2, net3, net4]):\n",
    "    # pass image through network\n",
    "    transform = transforms.Compose([\n",
    "                transforms.Scale(config.image_size),\n",
    "                transforms.CenterCrop(config.image_size),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "    \n",
    "    transform2 = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                     std=[0.5, 0.5, 0.5]),\n",
    "            ])\n",
    "    I_tens = transform(I) \n",
    "    background = tens_to_img(I_tens)\n",
    "    q = q_s[index]\n",
    "    v = v_s[index]\n",
    "    a = a_s[index]\n",
    "    q_len = q_lens[index]\n",
    "\n",
    "    net.eval()\n",
    "    hq = net.module.text(q, list(q_len.data))\n",
    "    hv = v/(v.norm(p=2, dim=1, keepdim=True).expand_as(v) + 1e-8)\n",
    "    ha = net.module.attention(hv, hq)\n",
    "    hv, attent = apply_attention(hv, ha)\n",
    "\n",
    "    # get glimpse 1\n",
    "    tens = attent[0, 0, 0, :]\n",
    "    tens.shape[0]\n",
    "    attent_img = tens.view(14,14).to('cpu').detach().numpy()\n",
    "    up_img = ndimage.zoom(attent_img, 32, order=0)\n",
    "    blur = ndimage.gaussian_filter(up_img, sigma=10)\n",
    "    blur3 = 191*blur\n",
    "    overlay = np.stack((blur3,blur3,blur3), axis=2)\n",
    "    glimpse1 = cv2.addWeighted(background, 0.4,overlay,0.1,0)\n",
    "\n",
    "    # get glimpse 2\n",
    "    tens = attent[0, 1, 0, :]\n",
    "    tens.shape[0]\n",
    "    attent_img = tens.view(14,14).to('cpu').detach().numpy()\n",
    "    up_img = ndimage.zoom(attent_img, 32, order=0)\n",
    "    blur = ndimage.gaussian_filter(up_img, sigma=10)\n",
    "    blur3 = 191*blur\n",
    "    overlay = np.stack((blur3,blur3,blur3), axis=2)\n",
    "    glimpse2 = cv2.addWeighted(background, 0.4,overlay,0.1,0)\n",
    "\n",
    "    white = [255,255,255] \n",
    "\n",
    "    glimpse1=cv2.copyMakeBorder(glimpse1,5,5,5,5,cv2.BORDER_CONSTANT,value=white)\n",
    "    glimpse2=cv2.copyMakeBorder(glimpse2,5,5,5,5,cv2.BORDER_CONSTANT,value=white)\n",
    "\n",
    "    allglimpses.append([glimpse1, glimpse2])\n",
    "        \n",
    "    \n",
    "    # answers \n",
    "    out = net(v, q, q_len)\n",
    "    _, answer = out.data.cpu().max(dim=1)\n",
    "    answ = (answer.view(-1))\n",
    "    ans_voc = dict((v,k) for k,v in datavqa.answer_to_index.items())\n",
    "    \n",
    "    if net_i == 0:\n",
    "        question = \"\"\n",
    "        for i in range(question_len):\n",
    "            print(rev_voc[question_ind[i]], end=' ')\n",
    "            question = question + rev_voc[question_ind[i]] + ' '\n",
    "        question = question + '?'    \n",
    "        print(\"?\")\n",
    "    print(\"Network ({0}) answer: {1}\".format(netname[net_i], ans_voc[answ.item()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
